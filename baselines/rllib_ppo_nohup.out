2025-12-15 19:49:14,272	WARNING ppo_torch_rl_module.py:8 -- DeprecationWarning: `ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule` has been deprecated. Use `ray.rllib.algorithms.ppo.torch.default_ppo_torch_rl_module.DefaultPPOTorchRLModule` instead. This will raise an error in the future!
2025-12-15 19:49:14,279	WARNING algorithm_config.py:2484 -- DeprecationWarning: `config.training(num_sgd_iter=..)` has been deprecated. Use `config.training(num_epochs=..)` instead. This will raise an error in the future!
wandb: Appending key for api.wandb.ai to your netrc file: /homes/vk545/.netrc
wandb: Currently logged in as: alienpenguin (alienpenguin-inc) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: setting up run x0gyvhnq
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /mnt/vurm/homes/homes/vk545/RL/wandb/run-20251215_194914-x0gyvhnq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-car-custom-stacked
wandb: â­ï¸ View project at https://wandb.ai/alienpenguin-inc/rl-training
wandb: ðŸš€ View run at https://wandb.ai/alienpenguin-inc/rl-training/runs/x0gyvhnq
wandb: Detected [agents] in use.
wandb: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.
wandb: For more information, check out the docs at: https://weave-docs.wandb.ai/
2025-12-15 19:49:17,780	INFO worker.py:2023 -- Started a local Ray instance.
/homes/vk545/Neuralese/miniconda3/envs/rl/lib/python3.12/site-packages/ray/_private/worker.py:2062: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
2025-12-15 19:49:20,134	WARNING train_ppo_car_custom.py:184 -- DeprecationWarning: `build` has been deprecated. Use `AlgorithmConfig.build_algo` instead. This will raise an error in the future!
2025-12-15 19:49:20,141	WARNING algorithm_config.py:5058 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html
/homes/vk545/Neuralese/miniconda3/envs/rl/lib/python3.12/site-packages/ray/rllib/algorithms/algorithm.py:525: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/homes/vk545/Neuralese/miniconda3/envs/rl/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/homes/vk545/Neuralese/miniconda3/envs/rl/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/homes/vk545/Neuralese/miniconda3/envs/rl/lib/python3.12/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
[2025-12-15 19:49:20,320 E 1554875 1554875] core_worker.cc:2223: Actor with class name: 'SingleAgentEnvRunner' and ID: 'abdaf96e1ea4cbc2bb87e19801000000' has constructor arguments in the object store and max_restarts > 0. If the arguments in the object store go out of scope or are lost, the actor restart will fail. See https://github.com/ray-project/ray/issues/53727 for more details.
[36m(SingleAgentEnvRunner pid=1557221)[0m /homes/vk545/Neuralese/miniconda3/envs/rl/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
[36m(SingleAgentEnvRunner pid=1557221)[0m   from pkg_resources import resource_stream, resource_exists
[36m(SingleAgentEnvRunner pid=1557221)[0m 2025-12-15 19:49:29,444	WARNING rl_module.py:446 -- Didn't create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. All algos use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.
[36m(SingleAgentEnvRunner pid=1557221)[0m DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
2025-12-15 19:49:30,999	WARNING rl_module.py:446 -- Didn't create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. All algos use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.
2025-12-15 19:49:30,999	WARNING rl_module.py:459 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!
2025-12-15 19:49:31,070	WARNING rl_module.py:446 -- Didn't create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. All algos use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.
2025-12-15 19:49:32,398	INFO trainable.py:161 -- Trainable.setup took 12.184 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.
2025-12-15 19:49:32,400	WARNING util.py:61 -- Install gputil for GPU system monitoring.
[36m(pid=gcs_server)[0m [2025-12-15 19:49:46,482 E 1555059 1555059] (gcs_server) gcs_server.cc:303: Failed to establish connection to the event+metrics exporter agent. Events and metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14
[36m(SingleAgentEnvRunner pid=1557230)[0m /homes/vk545/Neuralese/miniconda3/envs/rl/lib/python3.12/site-packages/pygame/pkgdata.py:25: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(SingleAgentEnvRunner pid=1557230)[0m   from pkg_resources import resource_stream, resource_exists[32m [repeated 7x across cluster][0m
[36m(SingleAgentEnvRunner pid=1557230)[0m 2025-12-15 19:49:30,728	WARNING rl_module.py:446 -- Didn't create a Catalog object for your RLModule! If you are not using the new API stack yet, make sure to switch it off in your config: `config.api_stack(enable_rl_module_and_learner=False, enable_env_runner_and_connector_v2=False)`. All algos use the new stack by default. Ignore this message, if your RLModule does not use a Catalog to build its sub-components.[32m [repeated 7x across cluster][0m
[36m(SingleAgentEnvRunner pid=1557230)[0m DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future![32m [repeated 7x across cluster][0m
[33m(raylet)[0m [2025-12-15 19:49:47,743 E 1555237 1555237] (raylet) main.cc:979: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14
[36m(pid=1555328)[0m [2025-12-15 19:49:49,344 E 1555328 1555458] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14
[2025-12-15 19:49:50,123 E 1554875 1555326] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14
wandb: uploading output.log
wandb: 
wandb: Run history:
wandb:                    entropy â–†â–†â–…â–„â–„â–„â–ƒâ–‚â–â–„â–‚â–…â–â–‡â–â–â–ˆâ–â–†â–…â–…â–‚â–…â–„â–„â–…â–…â–‡â–ƒâ–…â–‡â–‡â–‡â–‡â–ˆâ–†â–…â–ƒâ–…â–‚
wandb:           episode_len_mean â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:        episode_reward_mean â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–„â–„â–„â–„â–…â–…â–…â–„â–„â–„â–„â–…â–†â–†â–‡â–‡â–ˆ
wandb:                  iteration â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:               mean_kl_loss â–â–‚â–‚â–ƒâ–‚â–â–‚â–‡â–ˆâ–ƒâ–„â–‡â–„â–„â–…â–†â–„â–„â–„â–„â–„â–ƒâ–„â–…â–„â–…â–…â–„â–„â–†â–„â–„â–ƒâ–„â–ƒâ–„â–„â–„â–‚â–ƒ
wandb:                policy_loss â–‚â–…â–…â–â–‡â–â–„â–†â–‚â–„â–†â–ƒâ–‡â–ƒâ–ˆâ–„â–†â–‚â–†â–„â–…â–„â–…â–…â–ƒâ–ƒâ–ƒâ–„â–…â–‚â–…â–‡â–…â–…â–„â–†â–…â–ƒâ–ƒâ–†
wandb:                 total_loss â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–â–ƒâ–â–â–‚â–â–„â–‚â–‚â–„â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–„â–‚â–ƒâ–„â–†â–„â–„â–‚â–„â–…â–ƒâ–„â–†â–†â–…â–‡â–ˆâ–‡
wandb: training_iteration_time_ms â–‚â–‚â–‚â–…â–„â–ƒâ–â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–ˆâ–…â–ƒâ–„â–†â–…â–„â–„â–„â–…â–ƒâ–†â–…â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–…â–„â–ƒâ–ƒ
wandb:                    vf_loss â–„â–…â–„â–ƒâ–„â–…â–…â–„â–…â–ƒâ–„â–ƒâ–‚â–â–„â–â–„â–‚â–„â–ƒâ–‚â–„â–ƒâ–„â–„â–…â–„â–ƒâ–‚â–…â–…â–„â–‚â–ƒâ–†â–‡â–†â–†â–†â–ˆ
wandb: 
wandb: Run summary:
wandb:                    entropy 3.81515
wandb:           episode_len_mean 1000
wandb:        episode_reward_mean 218.02252
wandb:                  iteration 100
wandb:               mean_kl_loss 0.01462
wandb:                policy_loss 0.04684
wandb:                 total_loss 1.01838
wandb: training_iteration_time_ms 59267.52782
wandb:                    vf_loss 1.99831
wandb: 
wandb: ðŸš€ View run ppo-car-custom-stacked at: https://wandb.ai/alienpenguin-inc/rl-training/runs/x0gyvhnq
wandb: â­ï¸ View project at: https://wandb.ai/alienpenguin-inc/rl-training
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251215_194914-x0gyvhnq/logs
Script starting...
Starting training with Custom CNN RLModule...
Iteration 1: episode_reward_mean = 0.0
Iteration 2: episode_reward_mean = -53.51519254796549
Iteration 3: episode_reward_mean = -53.51519254796549
Iteration 4: episode_reward_mean = -48.419726642903846
Iteration 5: episode_reward_mean = -48.419726642903846
Iteration 6: episode_reward_mean = -42.05824444598169
Iteration 7: episode_reward_mean = -42.05824444598169
Iteration 8: episode_reward_mean = -39.51600737115709
Iteration 9: episode_reward_mean = -39.51600737115709
Iteration 10: episode_reward_mean = -38.09247038791017
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.56882858430538, 'restore_env_runners': 7.251547867525417e-05, 'training_step': 59.56779290423866, 'env_runner_sampling_timer': 10.039470259190626, 'learner_update_timer': 49.49423227415547, 'synch_weights': 0.02152290989493274, 'synch_env_connectors': 0.020731739255806892}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 40960.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 9.0, 'rlmodule_inference_timer': np.float64(0.004139183187610051), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.89176445710037e-06), 'numpy_to_tensor': np.float64(0.00011124798812336343), 'add_observations_from_episodes_to_batch': np.float64(2.4064078156802772e-05), 'batch_individual_items': np.float64(5.3409755849537666e-05), 'add_states_from_episodes_to_batch': np.float64(4.856073742844976e-06)}}, 'connector_pipeline_timer': np.float64(0.0003249082743419019)}, 'env_step_timer': np.float64(0.012751591619159936), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(4.860540308993401e-06), 'normalize_and_clip_actions': np.float64(0.00014216096282786652), 'get_actions': np.float64(0.00043662423008725365), 'un_batch_to_individual_items': np.float64(4.0957864887737865e-05), 'tensor_to_numpy': np.float64(0.0001424843142294495), 'listify_data_for_vector_env': np.float64(6.434122327804959e-05)}}, 'connector_pipeline_timer': np.float64(0.0010182271871308317)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(140.44059159428505), 'sample': np.float64(9.59133485471725), 'num_episodes_lifetime': 40.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(140.44059159428505), 'num_env_steps_sampled_lifetime': 40960.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 40960.0}, 'num_episodes': 8.0, 'agent_episode_return_mean': {'default_agent': -38.09247038791017}, 'episode_return_min': -48.64048338368646, 'episode_duration_sec_mean': 19.00602222764148, 'time_between_sampling': np.float64(50.0498345226288), 'episode_len_min': 1000, 'episode_return_mean': -38.09247038791017, 'episode_len_mean': 1000.0, 'episode_return_max': -26.199261992619945, 'module_episode_return_mean': {'default_policy': -38.09247038791017}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.48189968725549}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.08273562388173679, 'add_states_from_episodes_to_batch': 1.1583860553839582e-05, 'add_columns_from_episodes_to_train_batch': 0.09271309077050768, 'add_time_dim_to_batch_and_zero_pad': 4.8886472064163834e-05, 'general_advantage_estimation': 0.9964463299904346, 'numpy_to_tensor': 0.0007394138086381013, 'add_observations_from_episodes_to_batch': 0.00022689745403521445, 'batch_individual_items': 0.14083894597773838}}, 'connector_pipeline_timer': 1.3153099297268291}, 'num_env_steps_trained': 1324064, 'num_env_steps_trained_lifetime': 13207240, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 411520, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4104.384393668307, 'num_env_steps_trained_lifetime_throughput': 22356.01622116332, 'num_module_steps_trained_lifetime_throughput': 697.029859418487}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.29758188), 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 411520, 'gradients_default_optimizer_global_norm': np.float32(1.0439956), 'entropy': np.float32(4.4019303), 'weights_seq_no': 10.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.19027132), 'policy_loss': np.float32(0.10325897), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(0.47621763), 'curr_kl_coeff': 0.02500000037252903, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(0.47621763), 'mean_kl_loss': np.float32(0.0046678064), 'num_module_steps_trained_lifetime_throughput': 697.0284858360733}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 40960.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 10, 'trial_id': 'default', 'date': '2025-12-15_19-59-25', 'timestamp': 1765828765, 'time_this_iter_s': 59.44703960418701, 'time_total_s': 592.6503894329071, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 592.6503894329071, 'iterations_since_restore': 10, 'perf': {'cpu_util_percent': np.float64(53.976470588235294), 'ram_util_percent': np.float64(18.198823529411765)}})
Iteration 11: episode_reward_mean = -38.09247038791017
Iteration 12: episode_reward_mean = -32.0878547414168
Iteration 13: episode_reward_mean = -32.0878547414168
Iteration 14: episode_reward_mean = -31.430626571370713
Iteration 15: episode_reward_mean = -31.430626571370713
Iteration 16: episode_reward_mean = -28.081204243095776
Iteration 17: episode_reward_mean = -28.081204243095776
Iteration 18: episode_reward_mean = -20.15587579660295
Iteration 19: episode_reward_mean = -20.15587579660295
Iteration 20: episode_reward_mean = -9.056191019493092
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.5267441875761, 'restore_env_runners': 6.933544008092001e-05, 'training_step': 59.525699170698765, 'env_runner_sampling_timer': 10.06120172332034, 'learner_update_timer': 49.43135054999565, 'synch_weights': 0.021279140336554227, 'synch_env_connectors': 0.019861274379573583}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 81920.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 19.0, 'rlmodule_inference_timer': np.float64(0.004030489972151611), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.769998770424438e-06), 'numpy_to_tensor': np.float64(0.00011170783080262669), 'add_observations_from_episodes_to_batch': np.float64(2.4240247411087286e-05), 'batch_individual_items': np.float64(5.2803839989885634e-05), 'add_states_from_episodes_to_batch': np.float64(4.842532790874423e-06)}}, 'connector_pipeline_timer': np.float64(0.0003244456196883779)}, 'env_step_timer': np.float64(0.012610014404251583), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(4.781405126222183e-06), 'normalize_and_clip_actions': np.float64(0.00014020554908444638), 'get_actions': np.float64(0.00043394732234474124), 'un_batch_to_individual_items': np.float64(4.057183538582702e-05), 'tensor_to_numpy': np.float64(0.00014114406474129187), 'listify_data_for_vector_env': np.float64(6.424066099539486e-05)}}, 'connector_pipeline_timer': np.float64(0.0010092932451287936)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(168.18446303411906), 'sample': np.float64(9.60901181919176), 'num_episodes_lifetime': 80.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(168.18446303411906), 'num_env_steps_sampled_lifetime': 81920.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 81920.0}, 'num_episodes': 8.0, 'agent_episode_return_mean': {'default_agent': -9.056191019493092}, 'episode_return_min': -34.98452012383903, 'episode_duration_sec_mean': 18.871805450037265, 'time_between_sampling': np.float64(49.99949168248636), 'episode_len_min': 1000, 'episode_return_mean': -9.056191019493092, 'episode_len_mean': 1000.0, 'episode_return_max': 33.33333333333229, 'module_episode_return_mean': {'default_policy': -9.056191019493092}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.73607362429198}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.08053000006914024, 'add_states_from_episodes_to_batch': 1.12287577334753e-05, 'add_columns_from_episodes_to_train_batch': 0.09281889531226149, 'add_time_dim_to_batch_and_zero_pad': 4.652397890840286e-05, 'general_advantage_estimation': 0.9897963655176847, 'numpy_to_tensor': 0.0006946988844491582, 'add_observations_from_episodes_to_batch': 0.00022395659456283197, 'batch_individual_items': 0.1418882249403112}}, 'connector_pipeline_timer': 1.307463846534552}, 'num_env_steps_trained': 1324064, 'num_env_steps_trained_lifetime': 26414480, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 823040, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4104.73203241167, 'num_env_steps_trained_lifetime_throughput': 22337.304006844694, 'num_module_steps_trained_lifetime_throughput': 696.2599878989843}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.29387385), 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 823040, 'gradients_default_optimizer_global_norm': np.float32(2.8302348), 'entropy': np.float32(3.9174485), 'weights_seq_no': 20.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.73060364), 'policy_loss': np.float32(-0.023461837), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(0.7124681), 'curr_kl_coeff': 0.01875000074505806, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(0.7124681), 'mean_kl_loss': np.float32(0.02208917), 'num_module_steps_trained_lifetime_throughput': 696.2591502272182}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 81920.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 20, 'trial_id': 'default', 'date': '2025-12-15_20-09-17', 'timestamp': 1765829357, 'time_this_iter_s': 58.694170236587524, 'time_total_s': 1184.204350233078, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 1184.204350233078, 'iterations_since_restore': 20, 'perf': {'cpu_util_percent': np.float64(54.671428571428564), 'ram_util_percent': np.float64(18.055952380952377)}})
Iteration 21: episode_reward_mean = -9.056191019493092
Iteration 22: episode_reward_mean = -10.833077864861641
Iteration 23: episode_reward_mean = -10.833077864861641
Iteration 24: episode_reward_mean = -24.190443574919097
Iteration 25: episode_reward_mean = -24.190443574919097
Iteration 26: episode_reward_mean = -27.273527442059564
Iteration 27: episode_reward_mean = -27.273527442059564
Iteration 28: episode_reward_mean = -24.306407360609665
Iteration 29: episode_reward_mean = -24.306407360609665
Iteration 30: episode_reward_mean = -32.253109076836836
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.50306590328042, 'restore_env_runners': 6.590727610929761e-05, 'training_step': 59.50201941984723, 'env_runner_sampling_timer': 10.097483601504653, 'learner_update_timer': 49.37235489321233, 'synch_weights': 0.021077080653793028, 'synch_env_connectors': 0.018930876021260694}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 122880.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 29.0, 'rlmodule_inference_timer': np.float64(0.004116024683879968), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.682274782588044e-06), 'numpy_to_tensor': np.float64(0.00011050018766781776), 'add_observations_from_episodes_to_batch': np.float64(2.372677286136953e-05), 'batch_individual_items': np.float64(5.2205273227803114e-05), 'add_states_from_episodes_to_batch': np.float64(4.745129229814103e-06)}}, 'connector_pipeline_timer': np.float64(0.0003213606501013827)}, 'env_step_timer': np.float64(0.012842093774144386), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(4.7299940963389565e-06), 'normalize_and_clip_actions': np.float64(0.00013852492833446405), 'get_actions': np.float64(0.00042713118966508824), 'un_batch_to_individual_items': np.float64(4.01592114796464e-05), 'tensor_to_numpy': np.float64(0.0001391141304929222), 'listify_data_for_vector_env': np.float64(6.3593274195875e-05)}}, 'connector_pipeline_timer': np.float64(0.000996344897545418)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(268.0280427414851), 'sample': np.float64(9.63716680619288), 'num_episodes_lifetime': 120.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(268.0280427414851), 'num_env_steps_sampled_lifetime': 122880.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 122880.0}, 'num_episodes': 8.0, 'agent_episode_return_mean': {'default_agent': -32.253109076836836}, 'episode_return_min': -69.69696969696994, 'episode_duration_sec_mean': 19.267052512239808, 'time_between_sampling': np.float64(49.94397628119615), 'episode_len_min': 1000, 'episode_return_mean': -32.253109076836836, 'episode_len_mean': 1000.0, 'episode_return_max': 55.70934256055246, 'module_episode_return_mean': {'default_policy': -32.253109076836836}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.86020143476668}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.0777094170920541, 'add_states_from_episodes_to_batch': 1.0923124162201501e-05, 'add_columns_from_episodes_to_train_batch': 0.09249400491555707, 'add_time_dim_to_batch_and_zero_pad': 4.4067751479445115e-05, 'general_advantage_estimation': 0.984069022372715, 'numpy_to_tensor': 0.0006528249587480356, 'add_observations_from_episodes_to_batch': 0.0002217295508238184, 'batch_individual_items': 0.14238622583777708}}, 'connector_pipeline_timer': 1.2989552790766223}, 'num_env_steps_trained': 1324064, 'num_env_steps_trained_lifetime': 39621720, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 1234560, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4105.046430659747, 'num_env_steps_trained_lifetime_throughput': 22301.906981096952, 'num_module_steps_trained_lifetime_throughput': 695.0451895983765}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.19134238), 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 1234560, 'gradients_default_optimizer_global_norm': np.float32(5.6922083), 'entropy': np.float32(3.9583454), 'weights_seq_no': 30.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.9478907), 'policy_loss': np.float32(-0.19050482), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(0.8415339), 'curr_kl_coeff': 0.04218750074505806, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(0.8415339), 'mean_kl_loss': np.float32(0.02359917), 'num_module_steps_trained_lifetime_throughput': 695.0446792980885}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 122880.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 30, 'trial_id': 'default', 'date': '2025-12-15_20-19-11', 'timestamp': 1765829951, 'time_this_iter_s': 59.17413091659546, 'time_total_s': 1777.1718909740448, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 1777.1718909740448, 'iterations_since_restore': 30, 'perf': {'cpu_util_percent': np.float64(53.96904761904763), 'ram_util_percent': np.float64(18.14761904761905)}})
Iteration 31: episode_reward_mean = -32.253109076836836
Iteration 32: episode_reward_mean = -11.03638769734481
Iteration 33: episode_reward_mean = -11.03638769734481
Iteration 34: episode_reward_mean = 20.327418277599698
Iteration 35: episode_reward_mean = 20.327418277599698
Iteration 36: episode_reward_mean = 4.846120989417386
Iteration 37: episode_reward_mean = 4.846120989417386
Iteration 38: episode_reward_mean = -2.337291478353126
Iteration 39: episode_reward_mean = -2.337291478353126
Iteration 40: episode_reward_mean = -3.7470907875776125
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.489848174035465, 'restore_env_runners': 6.419657174945375e-05, 'training_step': 59.48879642027701, 'env_runner_sampling_timer': 10.129266056293607, 'learner_update_timer': 49.32833911647581, 'synch_weights': 0.02082493349943717, 'synch_env_connectors': 0.018464894843351627}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 163840.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 39.0, 'rlmodule_inference_timer': np.float64(0.004193116758570861), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(8.03844219293298e-06), 'numpy_to_tensor': np.float64(0.00011378152056435716), 'add_observations_from_episodes_to_batch': np.float64(2.503209001337552e-05), 'batch_individual_items': np.float64(5.500099941095565e-05), 'add_states_from_episodes_to_batch': np.float64(5.069743998884123e-06)}}, 'connector_pipeline_timer': np.float64(0.0003338309921090295)}, 'env_step_timer': np.float64(0.013585973546225132), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(5.013545859678757e-06), 'normalize_and_clip_actions': np.float64(0.00014754572308933218), 'get_actions': np.float64(0.00045087498493023154), 'un_batch_to_individual_items': np.float64(4.259610289236878e-05), 'tensor_to_numpy': np.float64(0.00014769090978263954), 'listify_data_for_vector_env': np.float64(6.705468137522618e-05)}}, 'connector_pipeline_timer': np.float64(0.0010539260522649256)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(384.22993616091037), 'sample': np.float64(9.661202345132914), 'num_episodes_lifetime': 160.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(384.22993616091037), 'num_env_steps_sampled_lifetime': 163840.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 163840.0}, 'num_episodes': 8.0, 'agent_episode_return_mean': {'default_agent': -3.7470907875776125}, 'episode_return_min': -43.217665615142394, 'episode_duration_sec_mean': 19.282118355873255, 'time_between_sampling': np.float64(49.906320388711734), 'episode_len_min': 1000, 'episode_return_mean': -3.7470907875776125, 'episode_len_mean': 1000.0, 'episode_return_max': 87.94326241135094, 'module_episode_return_mean': {'default_policy': -3.7470907875776125}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.86685354775317}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.07439998794421802, 'add_states_from_episodes_to_batch': 1.0552668364180181e-05, 'add_columns_from_episodes_to_train_batch': 0.09228747454151993, 'add_time_dim_to_batch_and_zero_pad': 4.202885332208091e-05, 'general_advantage_estimation': 0.9786282728971265, 'numpy_to_tensor': 0.0006139973311677935, 'add_observations_from_episodes_to_batch': 0.00021869254629297588, 'batch_individual_items': 0.1449497164616977}}, 'connector_pipeline_timer': 1.2924342532802895}, 'num_env_steps_trained': 1324064, 'num_env_steps_trained_lifetime': 52828960, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 1646080, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4105.330766799721, 'num_env_steps_trained_lifetime_throughput': 22261.488781580112, 'num_module_steps_trained_lifetime_throughput': 693.720308687943}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.222808), 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 1646080, 'gradients_default_optimizer_global_norm': np.float32(9.901141), 'entropy': np.float32(3.9043818), 'weights_seq_no': 40.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.931406), 'policy_loss': np.float32(-0.15535556), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(0.8305949), 'curr_kl_coeff': 0.14238281548023224, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(0.8958685), 'mean_kl_loss': np.float32(0.020121135), 'num_module_steps_trained_lifetime_throughput': 693.7200419095311}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 163840.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 40, 'trial_id': 'default', 'date': '2025-12-15_20-29-06', 'timestamp': 1765830546, 'time_this_iter_s': 59.919870138168335, 'time_total_s': 2370.9321303367615, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 2370.9321303367615, 'iterations_since_restore': 40, 'perf': {'cpu_util_percent': np.float64(56.59529411764705), 'ram_util_percent': np.float64(18.437647058823536)}})
Iteration 41: episode_reward_mean = -3.7470907875776125
Iteration 42: episode_reward_mean = 13.167669642193731
Iteration 43: episode_reward_mean = 33.99780878986883
Iteration 44: episode_reward_mean = 33.99780878986883
Iteration 45: episode_reward_mean = 22.64657674907875
Iteration 46: episode_reward_mean = 22.64657674907875
Iteration 47: episode_reward_mean = 34.379001981139
Iteration 48: episode_reward_mean = 34.379001981139
Iteration 49: episode_reward_mean = 36.508320529094235
Iteration 50: episode_reward_mean = 36.508320529094235
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.48843159139402, 'restore_env_runners': 6.173173005617104e-05, 'training_step': 59.48737771157468, 'env_runner_sampling_timer': 10.174983078646195, 'learner_update_timer': 49.28191502404558, 'synch_weights': 0.020773638962607664, 'synch_env_connectors': 0.017775801835836255}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 204800.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 49.0, 'rlmodule_inference_timer': np.float64(0.00414508175811288), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.809496078830625e-06), 'numpy_to_tensor': np.float64(0.00011309777747595904), 'add_observations_from_episodes_to_batch': np.float64(2.4339725095060084e-05), 'batch_individual_items': np.float64(5.317849514383789e-05), 'add_states_from_episodes_to_batch': np.float64(4.859502667090151e-06)}}, 'connector_pipeline_timer': np.float64(0.00032629926668936856)}, 'env_step_timer': np.float64(0.012899948899495705), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(4.850976143220668e-06), 'normalize_and_clip_actions': np.float64(0.000143199783893841), 'get_actions': np.float64(0.00044691722198749194), 'un_batch_to_individual_items': np.float64(4.146509655386981e-05), 'tensor_to_numpy': np.float64(0.00014586017396699393), 'listify_data_for_vector_env': np.float64(6.514143042531359e-05)}}, 'connector_pipeline_timer': np.float64(0.0010324310218112938)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(414.54166911499215), 'sample': np.float64(9.690841812990433), 'num_episodes_lifetime': 200.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(414.54166911499215), 'num_env_steps_sampled_lifetime': 204800.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 204800.0}, 'num_episodes': 0.0, 'agent_episode_return_mean': {'default_agent': 36.508320529094235}, 'episode_return_min': -45.85987261146546, 'episode_duration_sec_mean': 19.230368628865108, 'time_between_sampling': np.float64(49.879222745938115), 'episode_len_min': 1000, 'episode_return_mean': 36.508320529094235, 'episode_len_mean': 1000.0, 'episode_return_max': 167.36111111111344, 'module_episode_return_mean': {'default_policy': 36.508320529094235}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.80543785311126}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.07221312601958671, 'add_states_from_episodes_to_batch': 1.0223946268021345e-05, 'add_columns_from_episodes_to_train_batch': 0.0943160958162161, 'add_time_dim_to_batch_and_zero_pad': 3.9706145754090033e-05, 'general_advantage_estimation': 0.9754789694155171, 'numpy_to_tensor': 0.0005811831085754659, 'add_observations_from_episodes_to_batch': 0.00021575559808574657, 'batch_individual_items': 0.14338035597909538}}, 'connector_pipeline_timer': 1.287446740610474}, 'num_env_steps_trained': 1317384, 'num_env_steps_trained_lifetime': 66036200, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41088, 'num_module_steps_trained_lifetime': 2057600, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4105.5848095670635, 'num_env_steps_trained_lifetime_throughput': 22222.66278620787, 'num_module_steps_trained_lifetime_throughput': 692.4824507068124}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.45407975), 'num_module_steps_trained': 41088, 'num_module_steps_trained_lifetime': 2057600, 'gradients_default_optimizer_global_norm': np.float32(13.7138405), 'entropy': np.float32(4.125956), 'weights_seq_no': 50.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.9728686), 'policy_loss': np.float32(-0.036457732), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(1.0580409), 'curr_kl_coeff': 0.21357423067092896, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(1.2071428), 'mean_kl_loss': np.float32(0.013000391), 'num_module_steps_trained_lifetime_throughput': 692.4823031394894}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 204800.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 50, 'trial_id': 'default', 'date': '2025-12-15_20-39-02', 'timestamp': 1765831142, 'time_this_iter_s': 59.63284230232239, 'time_total_s': 2965.861890554428, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 2965.861890554428, 'iterations_since_restore': 50, 'perf': {'cpu_util_percent': np.float64(54.10117647058824), 'ram_util_percent': np.float64(18.07999999999999)}})
Iteration 51: episode_reward_mean = 48.603580372539376
Iteration 52: episode_reward_mean = 48.603580372539376
Iteration 53: episode_reward_mean = 64.81808410091382
Iteration 54: episode_reward_mean = 64.81808410091382
Iteration 55: episode_reward_mean = 72.60688002506468
Iteration 56: episode_reward_mean = 72.60688002506468
Iteration 57: episode_reward_mean = 45.59834063073349
Iteration 58: episode_reward_mean = 45.59834063073349
Iteration 59: episode_reward_mean = 59.699202819948695
Iteration 60: episode_reward_mean = 59.699202819948695
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.472547660999886, 'restore_env_runners': 5.989110911586001e-05, 'training_step': 59.47148527156874, 'env_runner_sampling_timer': 10.208718561090285, 'learner_update_timer': 49.23280717192474, 'synch_weights': 0.020802331307091335, 'synch_env_connectors': 0.017059365252206096}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 245760.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 59.0, 'rlmodule_inference_timer': np.float64(0.004094885333729021), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.892981826388684e-06), 'numpy_to_tensor': np.float64(0.00011160576368063346), 'add_observations_from_episodes_to_batch': np.float64(2.450284252658004e-05), 'batch_individual_items': np.float64(5.282254001375202e-05), 'add_states_from_episodes_to_batch': np.float64(4.886594863768518e-06)}}, 'connector_pipeline_timer': np.float64(0.0003247350146691777)}, 'env_step_timer': np.float64(0.012897738257348763), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(4.849679302586352e-06), 'normalize_and_clip_actions': np.float64(0.00014145596511038193), 'get_actions': np.float64(0.0004393093953388016), 'un_batch_to_individual_items': np.float64(4.1166514702404814e-05), 'tensor_to_numpy': np.float64(0.00014429297242400793), 'listify_data_for_vector_env': np.float64(6.416659654512436e-05)}}, 'connector_pipeline_timer': np.float64(0.0010203726629617396)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(414.4460342788467), 'sample': np.float64(9.713838756726958), 'num_episodes_lifetime': 240.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(414.4460342788467), 'num_env_steps_sampled_lifetime': 245760.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 245760.0}, 'num_episodes': 0.0, 'agent_episode_return_mean': {'default_agent': 59.699202819948695}, 'episode_return_min': -31.97278911564723, 'episode_duration_sec_mean': 19.236761341874416, 'time_between_sampling': np.float64(49.84645324362341), 'episode_len_min': 1000, 'episode_return_mean': 59.699202819948695, 'episode_len_mean': 1000.0, 'episode_return_max': 233.33333333333638, 'module_episode_return_mean': {'default_policy': 59.699202819948695}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.83523653480289}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.06977033633017829, 'add_states_from_episodes_to_batch': 9.944581387373913e-06, 'add_columns_from_episodes_to_train_batch': 0.0940133228842174, 'add_time_dim_to_batch_and_zero_pad': 3.793735822924016e-05, 'general_advantage_estimation': 0.9721845986821913, 'numpy_to_tensor': 0.0005529428478356806, 'add_observations_from_episodes_to_batch': 0.0002133146027816524, 'batch_individual_items': 0.14405501482541158}}, 'connector_pipeline_timer': 1.2819836721369573}, 'num_env_steps_trained': 1317384, 'num_env_steps_trained_lifetime': 79243440, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41088, 'num_module_steps_trained_lifetime': 2469120, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4105.813823096379, 'num_env_steps_trained_lifetime_throughput': 22221.972770102664, 'num_module_steps_trained_lifetime_throughput': 692.446269951403}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.29718262), 'num_module_steps_trained': 41088, 'num_module_steps_trained_lifetime': 2469120, 'gradients_default_optimizer_global_norm': np.float32(9.442753), 'entropy': np.float32(4.888344), 'weights_seq_no': 60.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.9750447), 'policy_loss': np.float32(0.06120041), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(0.5589134), 'curr_kl_coeff': 0.32036134600639343, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(0.9523066), 'mean_kl_loss': np.float32(0.016883824), 'num_module_steps_trained_lifetime_throughput': 692.4461518144699}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 245760.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 60, 'trial_id': 'default', 'date': '2025-12-15_20-48-56', 'timestamp': 1765831736, 'time_this_iter_s': 59.41950464248657, 'time_total_s': 3559.2352707386017, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 3559.2352707386017, 'iterations_since_restore': 60, 'perf': {'cpu_util_percent': np.float64(53.894117647058835), 'ram_util_percent': np.float64(18.20705882352941)}})
Iteration 61: episode_reward_mean = 31.11643256827131
Iteration 62: episode_reward_mean = 31.11643256827131
Iteration 63: episode_reward_mean = 51.86053397161952
Iteration 64: episode_reward_mean = 51.86053397161952
Iteration 65: episode_reward_mean = 54.844725302446186
Iteration 66: episode_reward_mean = 54.844725302446186
Iteration 67: episode_reward_mean = 69.53189161782231
Iteration 68: episode_reward_mean = 69.53189161782231
Iteration 69: episode_reward_mean = 116.90335391017558
Iteration 70: episode_reward_mean = 116.90335391017558
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.47040271075026, 'restore_env_runners': 5.7066578041008504e-05, 'training_step': 59.469327773232365, 'env_runner_sampling_timer': 10.248498707536509, 'learner_update_timer': 49.19147879280456, 'synch_weights': 0.020675624241064703, 'synch_env_connectors': 0.016342423028059966}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 286720.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 69.0, 'rlmodule_inference_timer': np.float64(0.004107804778458614), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.988402426868251e-06), 'numpy_to_tensor': np.float64(0.00011286514900456762), 'add_observations_from_episodes_to_batch': np.float64(2.474956289508139e-05), 'batch_individual_items': np.float64(5.407604205183251e-05), 'add_states_from_episodes_to_batch': np.float64(4.994885273279143e-06)}}, 'connector_pipeline_timer': np.float64(0.0003288714469740863)}, 'env_step_timer': np.float64(0.012875494009144468), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(4.897603551169665e-06), 'normalize_and_clip_actions': np.float64(0.00014335201295959476), 'get_actions': np.float64(0.00043629993253135803), 'un_batch_to_individual_items': np.float64(4.1164380708458276e-05), 'tensor_to_numpy': np.float64(0.00014279591669704233), 'listify_data_for_vector_env': np.float64(6.531375895176583e-05)}}, 'connector_pipeline_timer': np.float64(0.0010207481025661636)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(414.96699841674666), 'sample': np.float64(9.73375939058754), 'num_episodes_lifetime': 280.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(414.96699841674666), 'num_env_steps_sampled_lifetime': 286720.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 286720.0}, 'num_episodes': 0.0, 'agent_episode_return_mean': {'default_agent': 116.90335391017558}, 'episode_return_min': -51.2195121951229, 'episode_duration_sec_mean': 19.36345631339086, 'time_between_sampling': np.float64(49.82720729729717), 'episode_len_min': 1000, 'episode_return_mean': 116.90335391017558, 'episode_len_mean': 1000.0, 'episode_return_max': 362.89752650176393, 'module_episode_return_mean': {'default_policy': 116.90335391017558}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.82470401175296}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.06861679610279664, 'add_states_from_episodes_to_batch': 9.630800873276746e-06, 'add_columns_from_episodes_to_train_batch': 0.09378843980946758, 'add_time_dim_to_batch_and_zero_pad': 3.621596416107359e-05, 'general_advantage_estimation': 0.9702390213665466, 'numpy_to_tensor': 0.0005253160682077106, 'add_observations_from_episodes_to_batch': 0.0002178893941039364, 'batch_individual_items': 0.14695888324738512}}, 'connector_pipeline_timer': 1.2814804094268881}, 'num_env_steps_trained': 1317384, 'num_env_steps_trained_lifetime': 92450680, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41088, 'num_module_steps_trained_lifetime': 2880640, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4106.020938827225, 'num_env_steps_trained_lifetime_throughput': 22206.764629757163, 'num_module_steps_trained_lifetime_throughput': 691.9634190145626}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.43992323), 'num_module_steps_trained': 41088, 'num_module_steps_trained_lifetime': 2880640, 'gradients_default_optimizer_global_norm': np.float32(34.319275), 'entropy': np.float32(4.435627), 'weights_seq_no': 70.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.9674519), 'policy_loss': np.float32(-0.010450666), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(0.9804466), 'curr_kl_coeff': 0.32036134600639343, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(6.248815), 'mean_kl_loss': np.float32(0.014068021), 'num_module_steps_trained_lifetime_throughput': 691.9633431003186}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 286720.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 70, 'trial_id': 'default', 'date': '2025-12-15_20-58-52', 'timestamp': 1765832332, 'time_this_iter_s': 59.13163208961487, 'time_total_s': 4153.933307886124, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 4153.933307886124, 'iterations_since_restore': 70, 'perf': {'cpu_util_percent': np.float64(54.33058823529411), 'ram_util_percent': np.float64(18.22)}})
Iteration 71: episode_reward_mean = 104.269080968524
Iteration 72: episode_reward_mean = 104.269080968524
Iteration 73: episode_reward_mean = 76.51956478765443
Iteration 74: episode_reward_mean = 76.51956478765443
Iteration 75: episode_reward_mean = 72.85182632866906
Iteration 76: episode_reward_mean = 72.85182632866906
Iteration 77: episode_reward_mean = 60.66071463828645
Iteration 78: episode_reward_mean = 60.66071463828645
Iteration 79: episode_reward_mean = 75.91190237766827
Iteration 80: episode_reward_mean = 75.91190237766827
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.45703579736603, 'restore_env_runners': 5.521333785253165e-05, 'training_step': 59.45596618229234, 'env_runner_sampling_timer': 10.265537675435986, 'learner_update_timer': 49.161460513316314, 'synch_weights': 0.02075473985655145, 'synch_env_connectors': 0.01580726118530157}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 327680.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 79.0, 'rlmodule_inference_timer': np.float64(0.004143162396630621), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.829114526216221e-06), 'numpy_to_tensor': np.float64(0.00011083083505877755), 'add_observations_from_episodes_to_batch': np.float64(2.419056031651142e-05), 'batch_individual_items': np.float64(5.359720445341369e-05), 'add_states_from_episodes_to_batch': np.float64(4.9369966680010195e-06)}}, 'connector_pipeline_timer': np.float64(0.000325865915935311)}, 'env_step_timer': np.float64(0.013317883474566226), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(5.000956985294857e-06), 'normalize_and_clip_actions': np.float64(0.00014611549309557315), 'get_actions': np.float64(0.00044599424996579775), 'un_batch_to_individual_items': np.float64(4.231548501729523e-05), 'tensor_to_numpy': np.float64(0.0001464849227773348), 'listify_data_for_vector_env': np.float64(6.653346045465509e-05)}}, 'connector_pipeline_timer': np.float64(0.0010426530414014653)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(415.6305707948481), 'sample': np.float64(9.745793145028982), 'num_episodes_lifetime': 320.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(415.6305707948481), 'num_env_steps_sampled_lifetime': 327680.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 327680.0}, 'num_episodes': 0.0, 'agent_episode_return_mean': {'default_agent': 75.91190237766827}, 'episode_return_min': -56.22895622895703, 'episode_duration_sec_mean': 18.972486285439047, 'time_between_sampling': np.float64(49.79996065222227), 'episode_len_min': 1000, 'episode_return_mean': 75.91190237766827, 'episode_len_mean': 1000.0, 'episode_return_max': 300.0000000000001, 'module_episode_return_mean': {'default_policy': 75.91190237766827}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.8730951569897}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.0670104817866384, 'add_states_from_episodes_to_batch': 9.367810342039552e-06, 'add_columns_from_episodes_to_train_batch': 0.09356256272702038, 'add_time_dim_to_batch_and_zero_pad': 3.487103056583173e-05, 'general_advantage_estimation': 0.9686151493925873, 'numpy_to_tensor': 0.0004993247007473946, 'add_observations_from_episodes_to_batch': 0.00022268863892853868, 'batch_individual_items': 0.14941947656737617}}, 'connector_pipeline_timer': 1.2804103432456493}, 'num_env_steps_trained': 1317384, 'num_env_steps_trained_lifetime': 105657920, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41088, 'num_module_steps_trained_lifetime': 3292160, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4106.208250581656, 'num_env_steps_trained_lifetime_throughput': 22210.42780527952, 'num_module_steps_trained_lifetime_throughput': 692.0727844517057}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.2588889), 'num_module_steps_trained': 41088, 'num_module_steps_trained_lifetime': 3292160, 'gradients_default_optimizer_global_norm': np.float32(9.447343), 'entropy': np.float32(4.812528), 'weights_seq_no': 80.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.9863532), 'policy_loss': np.float32(0.0033196444), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(0.5944117), 'curr_kl_coeff': 0.48054200410842896, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(1.8378695), 'mean_kl_loss': np.float32(0.01350296), 'num_module_steps_trained_lifetime_throughput': 692.0727438531279}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 327680.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 80, 'trial_id': 'default', 'date': '2025-12-15_21-08-46', 'timestamp': 1765832926, 'time_this_iter_s': 59.59778046607971, 'time_total_s': 4747.375605583191, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 4747.375605583191, 'iterations_since_restore': 80, 'perf': {'cpu_util_percent': np.float64(54.39647058823529), 'ram_util_percent': np.float64(18.408235294117645)}})
Iteration 81: episode_reward_mean = 66.33547920547679
Iteration 82: episode_reward_mean = 66.33547920547679
Iteration 83: episode_reward_mean = 97.62384628746466
Iteration 84: episode_reward_mean = 97.31871358398985
Iteration 85: episode_reward_mean = 97.31871358398985
Iteration 86: episode_reward_mean = 128.08586652034452
Iteration 87: episode_reward_mean = 128.08586652034452
Iteration 88: episode_reward_mean = 146.51250306991588
Iteration 89: episode_reward_mean = 146.51250306991588
Iteration 90: episode_reward_mean = 134.17590902356272
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.43616549497491, 'restore_env_runners': 5.438545970659165e-05, 'training_step': 59.43509180771634, 'env_runner_sampling_timer': 10.27385559918824, 'learner_update_timer': 49.132932057263126, 'synch_weights': 0.020545132943986584, 'synch_env_connectors': 0.015332297492973724}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 368640.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 89.0, 'rlmodule_inference_timer': np.float64(0.00405285939182572), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.80831744504565e-06), 'numpy_to_tensor': np.float64(0.00011165505823674532), 'add_observations_from_episodes_to_batch': np.float64(2.4342630228963968e-05), 'batch_individual_items': np.float64(5.396200370729364e-05), 'add_states_from_episodes_to_batch': np.float64(4.952939297489335e-06)}}, 'connector_pipeline_timer': np.float64(0.00032648934402945766)}, 'env_step_timer': np.float64(0.012853325631717942), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(4.848628082220981e-06), 'normalize_and_clip_actions': np.float64(0.00014201761845621374), 'get_actions': np.float64(0.00044084749240186404), 'un_batch_to_individual_items': np.float64(4.14275753889189e-05), 'tensor_to_numpy': np.float64(0.00014311233415765075), 'listify_data_for_vector_env': np.float64(6.573182916809239e-05)}}, 'connector_pipeline_timer': np.float64(0.001025613594123081)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(175.80246699779036), 'sample': np.float64(9.75840794425015), 'num_episodes_lifetime': 368.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(175.80246699779036), 'num_env_steps_sampled_lifetime': 368640.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 368640.0}, 'num_episodes': 8.0, 'agent_episode_return_mean': {'default_agent': 134.17590902356272}, 'episode_return_min': -37.694704049845036, 'episode_duration_sec_mean': 19.156141992228534, 'time_between_sampling': np.float64(49.770292960199626), 'episode_len_min': 1000, 'episode_return_mean': 134.17590902356272, 'episode_len_mean': 1000.0, 'episode_return_max': 332.8358208955218, 'module_episode_return_mean': {'default_policy': 134.17590902356272}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.93636411594672}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.06515876167405787, 'add_states_from_episodes_to_batch': 9.212941809036222e-06, 'add_columns_from_episodes_to_train_batch': 0.09344786302914623, 'add_time_dim_to_batch_and_zero_pad': 3.3723720734320006e-05, 'general_advantage_estimation': 0.9661358729333314, 'numpy_to_tensor': 0.0004790904434745728, 'add_observations_from_episodes_to_batch': 0.0002236747061878698, 'batch_individual_items': 0.15205656958173708}}, 'connector_pipeline_timer': 1.278537830567874}, 'num_env_steps_trained': 1324064, 'num_env_steps_trained_lifetime': 118871840, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 3703808, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4106.4553229435605, 'num_env_steps_trained_lifetime_throughput': 22232.563913444177, 'num_module_steps_trained_lifetime_throughput': 692.7009893282424}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(0.30218577), 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 3703808, 'gradients_default_optimizer_global_norm': np.float32(8.836153), 'entropy': np.float32(4.5698385), 'weights_seq_no': 90.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.9481414), 'policy_loss': np.float32(-0.103981145), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(0.8801405), 'curr_kl_coeff': 0.7208130359649658, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(6.0156827), 'mean_kl_loss': np.float32(0.016363587), 'num_module_steps_trained_lifetime_throughput': 692.700991374389}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 368640.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 90, 'trial_id': 'default', 'date': '2025-12-15_21-18-40', 'timestamp': 1765833520, 'time_this_iter_s': 59.48874020576477, 'time_total_s': 5339.956257104874, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 5339.956257104874, 'iterations_since_restore': 90, 'perf': {'cpu_util_percent': np.float64(54.3607142857143), 'ram_util_percent': np.float64(18.196428571428573)}})
Iteration 91: episode_reward_mean = 134.17590902356272
Iteration 92: episode_reward_mean = 175.3607065843762
Iteration 93: episode_reward_mean = 175.3607065843762
Iteration 94: episode_reward_mean = 178.71276012211916
Iteration 95: episode_reward_mean = 178.71276012211916
Iteration 96: episode_reward_mean = 221.5548684966193
Iteration 97: episode_reward_mean = 221.5548684966193
Iteration 98: episode_reward_mean = 237.18468321624155
Iteration 99: episode_reward_mean = 237.18468321624155
Iteration 100: episode_reward_mean = 218.0225183297168
Checkpoint saved at: TrainingResult(checkpoint=Checkpoint(filesystem=local, path=/mnt/vurm/homes/homes/vk545/RL/models/train_ppo_car_custom), metrics={'timers': {'training_iteration': 59.42203536816569, 'restore_env_runners': 5.246494076335602e-05, 'training_step': 59.42096722019588, 'env_runner_sampling_timer': 10.29129854876619, 'learner_update_timer': 49.10182066209731, 'synch_weights': 0.020439631792181095, 'synch_env_connectors': 0.014845866087969008}, 'env_runners': {'num_agent_steps_sampled_lifetime': {'default_agent': 409600.0}, 'num_agent_steps_sampled': {'default_agent': 4096.0}, 'weights_seq_no': 99.0, 'rlmodule_inference_timer': np.float64(0.004211670988961216), 'env_to_module_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': np.float64(7.766972667229186e-06), 'numpy_to_tensor': np.float64(0.00011206183034369918), 'add_observations_from_episodes_to_batch': np.float64(2.4261275148960192e-05), 'batch_individual_items': np.float64(5.305291290548024e-05), 'add_states_from_episodes_to_batch': np.float64(4.897627073810637e-06)}}, 'connector_pipeline_timer': np.float64(0.00032517835338064573)}, 'env_step_timer': np.float64(0.013498568741973166), 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(4.867489805949831e-06), 'normalize_and_clip_actions': np.float64(0.00014041132784407563), 'get_actions': np.float64(0.00043724525720358726), 'un_batch_to_individual_items': np.float64(4.084380512504484e-05), 'tensor_to_numpy': np.float64(0.0001427770128889774), 'listify_data_for_vector_env': np.float64(6.385571058591989e-05)}}, 'connector_pipeline_timer': np.float64(0.001013821059277345)}, 'num_module_steps_sampled': {'default_policy': 4096.0}, 'env_to_module_sum_episodes_length_out': np.float64(145.47625902060594), 'sample': np.float64(9.777323927174852), 'num_episodes_lifetime': 408.0, 'num_env_steps_sampled': 4096.0, 'env_to_module_sum_episodes_length_in': np.float64(145.47625902060594), 'num_env_steps_sampled_lifetime': 409600.0, 'env_reset_timer': np.float64(0.06702704005874693), 'num_module_steps_sampled_lifetime': {'default_policy': 409600.0}, 'num_episodes': 8.0, 'agent_episode_return_mean': {'default_agent': 218.0225183297168}, 'episode_return_min': -36.70886075949473, 'episode_duration_sec_mean': 19.408944248920307, 'time_between_sampling': np.float64(49.74261704893466), 'episode_len_min': 1000, 'episode_return_mean': 218.0225183297168, 'episode_len_mean': 1000.0, 'episode_return_max': 384.37499999999307, 'module_episode_return_mean': {'default_policy': 218.0225183297168}, 'episode_len_max': 1000, 'num_env_steps_sampled_lifetime_throughput': 68.94208370540815}, 'learners': {'__all_modules__': {'learner_connector': {'timers': {'connectors': {'add_one_ts_to_episodes_and_truncate': 0.06338873582092946, 'add_states_from_episodes_to_batch': 8.986156075445062e-06, 'add_columns_from_episodes_to_train_batch': 0.09313175987203688, 'add_time_dim_to_batch_and_zero_pad': 3.2538521415599946e-05, 'general_advantage_estimation': 0.9638870723785591, 'numpy_to_tensor': 0.0004566714427537577, 'add_observations_from_episodes_to_batch': 0.0002205370313885659, 'batch_individual_items': 0.1516180806688461}}, 'connector_pipeline_timer': 1.2736911921693261}, 'num_env_steps_trained': 1324064, 'num_env_steps_trained_lifetime': 132079080, 'num_trainable_parameters': 2534455, 'learner_connector_sum_episodes_length_in': 4096.0, 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 4115328, 'num_non_trainable_parameters': 0, 'learner_connector_sum_episodes_length_out': 4106.604943726821, 'num_env_steps_trained_lifetime_throughput': 22237.52410037076, 'num_module_steps_trained_lifetime_throughput': 692.8624497350028}, 'default_policy': {'module_train_batch_size_mean': 128.0, 'total_loss': np.float32(1.0183836), 'num_module_steps_trained': 41216, 'num_module_steps_trained_lifetime': 4115328, 'gradients_default_optimizer_global_norm': np.float32(16.204956), 'entropy': np.float32(3.8151505), 'weights_seq_no': 100.0, 'default_optimizer_learning_rate': 0.0003, 'vf_explained_var': np.float32(0.4734556), 'policy_loss': np.float32(0.046843216), 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'vf_loss': np.float32(1.9983068), 'curr_kl_coeff': 0.7208130359649658, 'curr_entropy_coeff': 0.01, 'num_trainable_parameters': 2534455, 'vf_loss_unclipped': np.float32(25.886839), 'mean_kl_loss': np.float32(0.0146204475), 'num_module_steps_trained_lifetime_throughput': 692.8624530865801}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 409600.0, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 8}, 'done': False, 'training_iteration': 100, 'trial_id': 'default', 'date': '2025-12-15_21-28-34', 'timestamp': 1765834114, 'time_this_iter_s': 59.26752781867981, 'time_total_s': 5933.0394406318665, 'pid': 1554875, 'hostname': 'parkin', 'node_ip': '138.38.108.113', 'config': {'exploration_config': {}, 'extra_python_environs_for_driver': {}, 'extra_python_environs_for_worker': {}, 'placement_strategy': 'PACK', 'num_gpus': 1, '_fake_gpus': False, 'num_cpus_for_main_process': 1, 'eager_tracing': True, 'eager_max_retraces': 20, 'tf_session_args': {'intra_op_parallelism_threads': 2, 'inter_op_parallelism_threads': 2, 'gpu_options': {'allow_growth': True}, 'log_device_placement': False, 'device_count': {'CPU': 1}, 'allow_soft_placement': True}, 'local_tf_session_args': {'intra_op_parallelism_threads': 8, 'inter_op_parallelism_threads': 8}, 'torch_compile_learner': False, 'torch_compile_learner_what_to_compile': <TorchCompileWhatToCompile.FORWARD_TRAIN: 'forward_train'>, 'torch_compile_learner_dynamo_backend': 'inductor', 'torch_compile_learner_dynamo_mode': None, 'torch_compile_worker': False, 'torch_compile_worker_dynamo_backend': 'onnxrt', 'torch_compile_worker_dynamo_mode': None, 'torch_ddp_kwargs': {}, 'torch_skip_nan_gradients': False, 'env': 'CarRacing-Custom', 'env_config': {}, 'observation_space': None, 'action_space': None, 'clip_rewards': None, 'normalize_actions': True, 'clip_actions': False, '_is_atari': None, 'disable_env_checking': False, 'render_env': False, 'action_mask_key': 'action_mask', 'env_runner_cls': None, 'num_env_runners': 8, 'create_local_env_runner': True, 'num_envs_per_env_runner': 1, 'gym_env_vectorize_mode': 'sync', 'num_cpus_per_env_runner': 1, 'num_gpus_per_env_runner': 0, 'custom_resources_per_env_runner': {}, 'validate_env_runners_after_construction': True, 'episodes_to_numpy': True, 'max_requests_in_flight_per_env_runner': 1, 'sample_timeout_s': 60.0, '_env_to_module_connector': None, 'add_default_connectors_to_env_to_module_pipeline': True, '_module_to_env_connector': None, 'add_default_connectors_to_module_to_env_pipeline': True, 'merge_env_runner_states': 'training_only', 'broadcast_env_runner_states': True, 'episode_lookback_horizon': 1, 'rollout_fragment_length': 512, 'batch_mode': 'truncate_episodes', 'compress_observations': False, 'remote_worker_envs': False, 'remote_env_batch_wait_ms': 0, 'enable_tf1_exec_eagerly': False, 'sample_collector': <class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>, 'preprocessor_pref': 'deepmind', 'observation_filter': 'NoFilter', 'update_worker_filter_stats': True, 'use_worker_filter_stats': True, 'sampler_perf_stats_ema_coef': None, '_is_online': True, 'num_learners': 0, 'num_gpus_per_learner': 0, 'num_cpus_per_learner': 'auto', 'num_aggregator_actors_per_learner': 0, 'max_requests_in_flight_per_aggregator_actor': 3, 'local_gpu_idx': 0, 'max_requests_in_flight_per_learner': 3, 'gamma': 0.99, 'lr': 0.0003, 'grad_clip': 0.5, 'grad_clip_by': 'global_norm', '_train_batch_size_per_learner': 4096, 'train_batch_size': 4000, 'num_epochs': 10, 'minibatch_size': 128, 'shuffle_batch_per_epoch': True, 'model': {'fcnet_hiddens': [256, 256], 'fcnet_activation': 'tanh', 'fcnet_weights_initializer': None, 'fcnet_weights_initializer_config': None, 'fcnet_bias_initializer': None, 'fcnet_bias_initializer_config': None, 'conv_filters': None, 'conv_activation': 'relu', 'conv_kernel_initializer': None, 'conv_kernel_initializer_config': None, 'conv_bias_initializer': None, 'conv_bias_initializer_config': None, 'conv_transpose_kernel_initializer': None, 'conv_transpose_kernel_initializer_config': None, 'conv_transpose_bias_initializer': None, 'conv_transpose_bias_initializer_config': None, 'post_fcnet_hiddens': [], 'post_fcnet_activation': 'relu', 'post_fcnet_weights_initializer': None, 'post_fcnet_weights_initializer_config': None, 'post_fcnet_bias_initializer': None, 'post_fcnet_bias_initializer_config': None, 'free_log_std': False, 'log_std_clip_param': 20.0, 'no_final_linear': False, 'vf_share_layers': False, 'use_lstm': False, 'max_seq_len': 20, 'lstm_cell_size': 256, 'lstm_use_prev_action': False, 'lstm_use_prev_reward': False, 'lstm_weights_initializer': None, 'lstm_weights_initializer_config': None, 'lstm_bias_initializer': None, 'lstm_bias_initializer_config': None, '_time_major': False, 'use_attention': False, 'attention_num_transformer_units': 1, 'attention_dim': 64, 'attention_num_heads': 1, 'attention_head_dim': 32, 'attention_memory_inference': 50, 'attention_memory_training': 50, 'attention_position_wise_mlp_dim': 32, 'attention_init_gru_gate_bias': 2.0, 'attention_use_n_prev_actions': 0, 'attention_use_n_prev_rewards': 0, 'framestack': True, 'dim': 84, 'grayscale': False, 'zero_mean': True, 'custom_model': None, 'custom_model_config': {}, 'custom_action_dist': None, 'custom_preprocessor': None, 'encoder_latent_dim': None, 'always_check_shapes': False, 'lstm_use_prev_action_reward': -1, '_use_default_native_models': -1, '_disable_preprocessor_api': False, '_disable_action_flattening': False}, '_learner_connector': None, 'add_default_connectors_to_learner_pipeline': True, 'learner_config_dict': {}, 'optimizer': {}, '_learner_class': None, 'callbacks_on_algorithm_init': None, 'callbacks_on_env_runners_recreated': None, 'callbacks_on_offline_eval_runners_recreated': None, 'callbacks_on_checkpoint_loaded': None, 'callbacks_on_environment_created': None, 'callbacks_on_episode_created': None, 'callbacks_on_episode_start': None, 'callbacks_on_episode_step': None, 'callbacks_on_episode_end': None, 'callbacks_on_evaluate_start': None, 'callbacks_on_evaluate_end': None, 'callbacks_on_evaluate_offline_start': None, 'callbacks_on_evaluate_offline_end': None, 'callbacks_on_sample_end': None, 'callbacks_on_train_result': None, 'explore': True, 'enable_rl_module_and_learner': True, 'enable_env_runner_and_connector_v2': True, '_prior_exploration_config': {'type': 'StochasticSampling'}, 'count_steps_by': 'env_steps', 'policy_map_capacity': 100, 'policy_mapping_fn': <function AlgorithmConfig.DEFAULT_POLICY_MAPPING_FN at 0x77489c555b20>, 'policies_to_train': None, 'policy_states_are_swappable': False, 'observation_fn': None, 'offline_data_class': None, 'input_read_method': 'read_parquet', 'input_read_method_kwargs': {}, 'input_read_schema': {}, 'input_read_episodes': False, 'input_read_sample_batches': False, 'input_read_batch_size': None, 'input_filesystem': None, 'input_filesystem_kwargs': {}, 'input_compress_columns': ['obs', 'new_obs'], 'input_spaces_jsonable': True, 'materialize_data': False, 'materialize_mapped_data': True, 'map_batches_kwargs': {}, 'iter_batches_kwargs': {}, 'ignore_final_observation': False, 'prelearner_class': None, 'prelearner_buffer_class': None, 'prelearner_buffer_kwargs': {}, 'prelearner_module_synch_period': 10, 'dataset_num_iters_per_learner': None, 'input_config': {}, 'actions_in_input_normalized': False, 'postprocess_inputs': False, 'shuffle_buffer_size': 0, 'output': None, 'output_config': {}, 'output_compress_columns': ['obs', 'new_obs'], 'output_max_file_size': 67108864, 'output_max_rows_per_file': None, 'output_write_remaining_data': False, 'output_write_method': 'write_parquet', 'output_write_method_kwargs': {}, 'output_filesystem': None, 'output_filesystem_kwargs': {}, 'output_write_episodes': True, 'offline_sampling': False, 'evaluation_interval': None, 'evaluation_duration': 10, 'evaluation_duration_unit': 'episodes', 'evaluation_sample_timeout_s': 120.0, 'evaluation_auto_duration_min_env_steps_per_sample': 100, 'evaluation_auto_duration_max_env_steps_per_sample': 2000, 'evaluation_parallel_to_training': False, 'evaluation_force_reset_envs_before_iteration': True, 'evaluation_config': None, 'off_policy_estimation_methods': {}, 'ope_split_batch_by_episode': True, 'evaluation_num_env_runners': 0, 'in_evaluation': False, 'sync_filters_on_rollout_workers_timeout_s': 10.0, 'offline_evaluation_interval': None, 'num_offline_eval_runners': 0, 'offline_evaluation_type': None, 'offline_eval_runner_class': None, 'offline_loss_for_module_fn': None, 'offline_evaluation_duration': 1, 'offline_evaluation_parallel_to_training': False, 'offline_evaluation_timeout_s': 120.0, 'num_cpus_per_offline_eval_runner': 1, 'num_gpus_per_offline_eval_runner': 0, 'custom_resources_per_offline_eval_runner': {}, 'restart_failed_offline_eval_runners': True, 'ignore_offline_eval_runner_failures': False, 'max_num_offline_eval_runner_restarts': 1000, 'offline_eval_runner_restore_timeout_s': 1800.0, 'max_requests_in_flight_per_offline_eval_runner': 1, 'validate_offline_eval_runners_after_construction': True, 'offline_eval_runner_health_probe_timeout_s': 30.0, 'offline_eval_rl_module_inference_only': False, 'broadcast_offline_eval_runner_states': False, 'offline_eval_batch_size_per_runner': 256, 'dataset_num_iters_per_eval_runner': 1, 'keep_per_episode_custom_metrics': False, 'metrics_episode_collection_timeout_s': 60.0, 'metrics_num_episodes_for_smoothing': 100, 'min_time_s_per_iteration': None, 'min_train_timesteps_per_iteration': 0, 'min_sample_timesteps_per_iteration': 0, 'log_gradients': False, 'export_native_model_files': False, 'checkpoint_trainable_policies_only': False, 'logger_creator': None, 'logger_config': None, 'log_level': 'WARN', 'log_sys_usage': True, 'fake_sampler': False, 'seed': None, 'restart_failed_env_runners': True, 'ignore_env_runner_failures': False, 'max_num_env_runner_restarts': 1000, 'delay_between_env_runner_restarts_s': 60.0, 'restart_failed_sub_environments': False, 'num_consecutive_env_runner_failures_tolerance': 100, 'env_runner_health_probe_timeout_s': 30.0, 'env_runner_restore_timeout_s': 1800.0, '_model_config': {}, '_rl_module_spec': RLModuleSpec(module_class=<class '__main__.CustomPPORLModule'>, observation_space=None, action_space=None, inference_only=False, learner_only=False, model_config=None, catalog_class=None, load_state_path=None, model_config_dict=None), 'algorithm_config_overrides_per_module': {}, '_per_module_overrides': {}, '_validate_config': True, '_use_msgpack_checkpoints': False, '_torch_grad_scaler_class': None, '_torch_lr_scheduler_classes': None, '_tf_policy_handles_more_than_one_loss': False, '_disable_preprocessor_api': False, '_disable_action_flattening': False, '_disable_initialize_loss_from_dummy_batch': False, '_dont_auto_sync_env_runner_states': False, 'env_task_fn': -1, 'enable_connectors': -1, 'simple_optimizer': False, 'policy_map_cache': -1, 'worker_cls': -1, 'synchronize_filters': -1, 'enable_async_evaluation': -1, 'custom_async_evaluation_function': -1, '_enable_rl_module_api': -1, 'auto_wrap_old_gym_envs': -1, 'always_attach_evaluation_results': -1, 'replay_sequence_length': None, '_disable_execution_plan_api': -1, 'use_critic': True, 'use_gae': True, 'use_kl_loss': True, 'kl_coeff': 0.2, 'kl_target': 0.01, 'vf_loss_coeff': 0.5, 'entropy_coeff': 0.01, 'clip_param': 0.2, 'vf_clip_param': 10.0, 'entropy_coeff_schedule': None, 'lr_schedule': None, 'sgd_minibatch_size': -1, 'vf_share_layers': -1, 'class': <class 'ray.rllib.algorithms.ppo.ppo.PPOConfig'>, 'lambda': 0.95, 'input': 'sampler', 'policies': {'default_policy': (None, None, None, None)}, 'callbacks': <class 'ray.rllib.callbacks.callbacks.RLlibCallback'>, 'create_env_on_driver': False, 'custom_eval_function': None, 'framework': 'torch'}, 'time_since_restore': 5933.0394406318665, 'iterations_since_restore': 100, 'perf': {'cpu_util_percent': np.float64(53.80833333333333), 'ram_util_percent': np.float64(18.41428571428572)}})
[36m(SingleAgentEnvRunner pid=1557230)[0m [2025-12-15 19:49:52,143 E 1557230 1557735] core_worker_process.cc:837: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14[32m [repeated 31x across cluster][0m
